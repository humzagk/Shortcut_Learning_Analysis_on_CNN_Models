{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Shortcut Learning Analysis: Texture vs. Shape Bias in CNNs\n",
        "\n",
        "## 1. Project Overview\n",
        "**Author:** Humza Gohar Kabir\n",
        "\n",
        "\n",
        "**Objective:** To investigate the \"Shortcut Learning\" phenomenon in Deep Convolutional Neural Networks (CNNs), specifically hypothesis that standard CNNs rely on superficial texture statistics rather than high-level semantic shape features.\n",
        "\n",
        "## 2. Problem Statement\n",
        "Deep Learning models often achieve high performance on benchmark datasets but fail to generalize to out-of-distribution samples. This project quantifies the **\"Texture Bias\"** of ResNet architectures by evaluating their performance on datasets where texture cues are rigorously removed.\n",
        "\n",
        "## 3. Methodology\n",
        "We conduct a comparative analysis between **ResNet-18** (Low Capacity) and **ResNet-101** (High Capacity) using the **Imagenette** dataset (10 classes).\n",
        "\n",
        "The experiment follows a three-phase protocol:\n",
        "1.  **Data Preprocessing:** Generating deterministic variations of the dataset:\n",
        "    * *Edge-Extracted:* Using Canny Edge Detection to isolate shape.\n",
        "    * *Segmented:* Using DeepLabV3 to remove background context.\n",
        "2.  **Bias Quantification:** Training models on standard RGB images and evaluating the **\"Degradation Gap\"** when tested on Edge/Segmented data.\n",
        "3.  **Control Experiment:** Training models specifically on Edge data to verify if shape-based learning is feasible (\"Domain Mastery\").\n",
        "\n",
        "## 4. Key Hypotheses\n",
        "* **H1:** Standard CNNs will suffer a catastrophic performance drop (>50%) when texture is removed, proving reliance on shortcuts.\n",
        "* **H2:** Increasing model depth (ResNet-101) will not significantly mitigate this bias without changes to the training objective."
      ],
      "metadata": {
        "id": "UeGSAgx514nn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computations were performed on the TRUBA High-Performance Computing cluster, which is why the code files below include the .py and sbatch slurm scripts, which are identifiable by the first commented line in each cell. All these code files are compiled together into a ipynb file not to run but for the ease of reading the code. Implementations can be made though your preferred Truba console (such as Termius etc), and these files can be written there though nano commands like (nano ~/CNN_Shortcut_Project/src/preprocess.py) or (nano ~/CNN_Shortcut_Project/slurm_scripts/run_train.sh)\n",
        "\n",
        "Dataset used: https://github.com/fastai/imagenette\n"
      ],
      "metadata": {
        "id": "_3TbssSyYjHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess_data.py\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import models, transforms\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "\n",
        "# ARGS\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--input_dir', type=str, required=True, help=\"Path to raw imagenette folder\")\n",
        "parser.add_argument('--output_dir', type=str, required=True, help=\"Base path for processed data\")\n",
        "parser.add_argument('--mode', type=str, choices=['edges', 'segmentation'], required=True)\n",
        "args = parser.parse_args()\n",
        "\n",
        "# SETUP DEVICE\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Running mode: {args.mode} on {device}\")\n",
        "\n",
        "# MODEL SETUP (Only for segmentation)\n",
        "seg_model = None\n",
        "seg_transform = None\n",
        "if args.mode == 'segmentation':\n",
        "    weights = DeepLabV3_ResNet50_Weights.DEFAULT\n",
        "    seg_model = deeplabv3_resnet50(weights=weights).to(device)\n",
        "    seg_model.eval()\n",
        "    seg_transform = weights.transforms()\n",
        "\n",
        "def process_edges(img_path, save_path):\n",
        "    # Read Image\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None: return\n",
        "\n",
        "    # Canny Edge Detection\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "\n",
        "    # Stack to make 3-channel (so standard CNNs accept it)\n",
        "    edges_rgb = np.stack([edges]*3, axis=-1)\n",
        "\n",
        "    cv2.imwrite(save_path, edges_rgb)\n",
        "\n",
        "def process_segmentation(img_path, save_path):\n",
        "    # Load and Transform\n",
        "    try:\n",
        "        img_pil = Image.open(img_path).convert(\"RGB\")\n",
        "        original_np = np.array(img_pil)\n",
        "    except:\n",
        "        return\n",
        "\n",
        "    # Model scales image up to ~520px internally\n",
        "    input_tensor = seg_transform(img_pil).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = seg_model(input_tensor)['out'][0]\n",
        "\n",
        "    # Generate Mask (Class 0 is background)\n",
        "    output_predictions = output.argmax(0).byte().cpu().numpy()\n",
        "\n",
        "    # Resize mask back to original image size\n",
        "    # cv2.resize expects (Width, Height), but numpy shape is (Height, Width)\n",
        "    h, w = original_np.shape[:2]\n",
        "    mask_resized = cv2.resize(output_predictions, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    # Create Binary Mask (0=Background, 1=Object)\n",
        "    mask = (mask_resized > 0).astype(np.uint8)\n",
        "\n",
        "    # Apply Mask to Original Image\n",
        "    mask_3ch = np.stack([mask]*3, axis=-1)\n",
        "    foreground = original_np * mask_3ch\n",
        "\n",
        "    # Convert back to BGR for OpenCV saving\n",
        "    foreground_bgr = cv2.cvtColor(foreground, cv2.COLOR_RGB2BGR)\n",
        "    cv2.imwrite(save_path, foreground_bgr)\n",
        "\n",
        "# MAIN LOOP\n",
        "splits = ['train', 'val']\n",
        "\n",
        "for split in splits:\n",
        "    split_path = os.path.join(args.input_dir, split)\n",
        "    if not os.path.exists(split_path): continue\n",
        "\n",
        "    # Iterate over classes\n",
        "    classes = os.listdir(split_path)\n",
        "    for cls in classes:\n",
        "        cls_dir = os.path.join(split_path, cls)\n",
        "        if not os.path.isdir(cls_dir): continue\n",
        "\n",
        "        # Create Output Directory\n",
        "        out_cls_dir = os.path.join(args.output_dir, args.mode, split, cls)\n",
        "        os.makedirs(out_cls_dir, exist_ok=True)\n",
        "\n",
        "        # Process Images\n",
        "        images = os.listdir(cls_dir)\n",
        "        print(f\"Processing {split}/{cls}...\")\n",
        "\n",
        "        for img_name in images:\n",
        "            src = os.path.join(cls_dir, img_name)\n",
        "            dst = os.path.join(out_cls_dir, img_name)\n",
        "\n",
        "            if args.mode == 'edges':\n",
        "                process_edges(src, dst)\n",
        "            elif args.mode == 'segmentation':\n",
        "                process_segmentation(src, dst)\n",
        "\n",
        "print(\"Processing Complete.\")"
      ],
      "metadata": {
        "id": "yI23zNARe84s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# slurm_scripts/run_preprocess.sh\n",
        "\n",
        "#!/bin/bash\n",
        "#SBATCH -J preprocess_data\n",
        "#SBATCH -p barbun\n",
        "#SBATCH -N 1\n",
        "#SBATCH -n 1\n",
        "#SBATCH -c 40\n",
        "#SBATCH --time=04:00:00\n",
        "#SBATCH --output=preprocess_%j.log\n",
        "\n",
        "echo \"Job started on $(hostname)\"\n",
        "\n",
        "# 1. Load Environment\n",
        "module purge\n",
        "# We need to ensure python 3 is available\n",
        "export PATH=$HOME/.local/bin:$PATH\n",
        "\n",
        "# 2. Define Paths\n",
        "USER_NAME=$(whoami)\n",
        "SRC_DIR=\"/arf/scratch/$USER_NAME/shortcut_data/raw/imagenette2-160\"\n",
        "DEST_DIR=\"/arf/scratch/$USER_NAME/shortcut_data/processed\"\n",
        "SCRIPT_PATH=\"$HOME/CNN_Shortcut_Project/src/preprocess_data.py\"\n",
        "\n",
        "# 3. Run Edge Detection\n",
        "echo \"Starting Edge Detection...\"\n",
        "# python $SCRIPT_PATH --input_dir $SRC_DIR --output_dir $DEST_DIR --mode edges\n",
        "\n",
        "# 4. Run Segmentation (Background Removal)\n",
        "echo \"Starting Segmentation...\"\n",
        "python $SCRIPT_PATH --input_dir $SRC_DIR --output_dir $DEST_DIR --mode segmentation\n",
        "\n",
        "echo \"Job finished.\""
      ],
      "metadata": {
        "id": "zjSPBgG6dzQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Svzlna0PtQC"
      },
      "outputs": [],
      "source": [
        "# train.py\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import argparse\n",
        "import copy\n",
        "import sys\n",
        "\n",
        "# ARGUMENTS\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--data_root', type=str, required=True, help=\"Root of dataset\")\n",
        "parser.add_argument('--model', type=str, choices=['resnet18', 'resnet101'], default='resnet18')\n",
        "parser.add_argument('--train_mode', type=str, choices=['original', 'edges', 'segmentation', 'grayscale', 'occlusion'], required=True)\n",
        "parser.add_argument('--test_mode', type=str, choices=['original', 'edges', 'segmentation', 'grayscale', 'occlusion'], required=True)\n",
        "parser.add_argument('--epochs', type=int, default=15)\n",
        "parser.add_argument('--batch_size', type=int, default=32)\n",
        "parser.add_argument('--output_dir', type=str, default='./results')\n",
        "args = parser.parse_args()\n",
        "\n",
        "# SETUP DEVICE\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Exp: Train on {args.train_mode} -> Test on {args.test_mode} | Model: {args.model}\")\n",
        "\n",
        "# 1. DEFINE TRANSFORMS (Dynamic Augmentation)\n",
        "def get_transforms(mode, is_training=False):\n",
        "    trans_list = [transforms.Resize((224, 224))]\n",
        "\n",
        "    # Mode-Specific Pre-processing\n",
        "    if mode == 'grayscale':\n",
        "        trans_list.append(transforms.Grayscale(num_output_channels=3))\n",
        "\n",
        "    # Standard Tensors\n",
        "    trans_list.append(transforms.ToTensor())\n",
        "    trans_list.append(transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
        "\n",
        "    # Occlusion (Cutout) - Applied after Normalization\n",
        "    if mode == 'occlusion':\n",
        "        # Probability 1.0 means we ALWAYS occlude something (since we want to test robustness)\n",
        "        trans_list.append(transforms.RandomErasing(p=1.0, scale=(0.02, 0.2)))\n",
        "\n",
        "    return transforms.Compose(trans_list)\n",
        "\n",
        "# 2. DATA LOADER SETUP\n",
        "def get_data_dir(root, mode):\n",
        "    # Base paths\n",
        "    if mode == 'original':\n",
        "        base = os.path.join(root, 'raw', 'imagenette2-160')\n",
        "    elif mode in ['edges', 'segmentation']:\n",
        "        base = os.path.join(root, 'processed', mode)\n",
        "    elif mode in ['grayscale', 'occlusion']:\n",
        "        base = os.path.join(root, 'raw', 'imagenette2-160')\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown mode: {mode}\")\n",
        "    return base\n",
        "\n",
        "# Train Loader (Append '/train')\n",
        "train_dir = os.path.join(get_data_dir(args.data_root, args.train_mode), 'train')\n",
        "train_dataset = datasets.ImageFolder(train_dir, get_transforms(args.train_mode, is_training=True))\n",
        "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "# Test Loader (Append '/val')\n",
        "test_dir = os.path.join(get_data_dir(args.data_root, args.test_mode), 'val')\n",
        "test_dataset = datasets.ImageFolder(test_dir, get_transforms(args.test_mode, is_training=False))\n",
        "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "class_names = train_dataset.classes\n",
        "num_classes = len(class_names)\n",
        "print(f\"Data Loaded. Classes: {num_classes}\")\n",
        "\n",
        "# 3. MODEL SETUP\n",
        "if args.model == 'resnet18':\n",
        "    model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "elif args.model == 'resnet101':\n",
        "    model = models.resnet101(weights='IMAGENET1K_V1')\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "# 4. TRAINING LOOP\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(args.epochs):\n",
        "    print(f'Epoch {epoch+1}/{args.epochs}')\n",
        "\n",
        "    # Train Phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "    scheduler.step()\n",
        "\n",
        "    # Test Phase\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "    print(f\"Train Loss: {running_loss/len(train_dataset):.4f} | Test Acc: {epoch_acc:.4f} | Test F1: {epoch_f1:.4f}\")\n",
        "\n",
        "    # Save Best\n",
        "    if epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        os.makedirs(args.output_dir, exist_ok=True)\n",
        "        save_path = os.path.join(args.output_dir, f\"{args.model}_Tr-{args.train_mode}_Te-{args.test_mode}.pth\")\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "print(f\"Best Accuracy: {best_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# slurm_scripts/run_train.sh\n",
        "\n",
        "\n",
        "#!/bin/bash\n",
        "#SBATCH -J cnn_exp_full\n",
        "#SBATCH -p akya-cuda         # Primary GPU partition\n",
        "#SBATCH -N 1\n",
        "#SBATCH -n 1\n",
        "#SBATCH -c 10                # CPU cores for data loading\n",
        "#SBATCH --gres=gpu:1         # Request 1 GPU\n",
        "#SBATCH --time=24:00:00      # 24 hours to cover all experiments\n",
        "#SBATCH --output=/arf/scratch/%u/shortcut_data/results/train_%j.log\n",
        "\n",
        "echo \"Job started on $(hostname)\"\n",
        "\n",
        "# 1. Load Environment\n",
        "module purge\n",
        "export PATH=$HOME/.local/bin:$PATH\n",
        "\n",
        "# 2. Define Variables\n",
        "USER_NAME=$(whoami)\n",
        "# Data and Results in Scratch\n",
        "DATA_ROOT=\"/arf/scratch/$USER_NAME/shortcut_data\"\n",
        "OUTPUT_DIR=\"/arf/scratch/$USER_NAME/shortcut_data/results\"\n",
        "SCRIPT_PATH=\"$HOME/CNN_Shortcut_Project/src/train.py\"\n",
        "\n",
        "mkdir -p $OUTPUT_DIR\n",
        "\n",
        "# Define Lists\n",
        "MODELS=(\"resnet18\" \"resnet101\")\n",
        "MODIFICATIONS=(\"edges\" \"segmentation\" \"grayscale\" \"occlusion\")\n",
        "\n",
        "# MAIN EXPERIMENT LOOP\n",
        "\n",
        "for MODEL in \"${MODELS[@]}\"; do\n",
        "    echo \"STARTING BATCH FOR MODEL: $MODEL\"\n",
        "\n",
        "\n",
        "\n",
        "    # BLOCK A: BASELINE & EXPERIMENT 1 (Bias Check)\n",
        "    # Goal: Train on Original, Test on Everything (Original + Modified)\n",
        "\n",
        "    echo \"[Exp 1] Training on ORIGINAL Data \"\n",
        "\n",
        "    # 1. Baseline: Train Original -> Test Original\n",
        "    echo \"Running: Train Original -> Test Original\"\n",
        "    python $SCRIPT_PATH \\\n",
        "        --data_root $DATA_ROOT \\\n",
        "        --output_dir $OUTPUT_DIR \\\n",
        "        --model $MODEL \\\n",
        "        --epochs 15 \\\n",
        "        --train_mode original \\\n",
        "        --test_mode original\n",
        "\n",
        "    # 2. Bias Checks: Train Original -> Test Modified\n",
        "    for MOD in \"${MODIFICATIONS[@]}\"; do\n",
        "        echo \"Running: Train Original -> Test $MOD\"\n",
        "        python $SCRIPT_PATH \\\n",
        "            --data_root $DATA_ROOT \\\n",
        "            --output_dir $OUTPUT_DIR \\\n",
        "            --model $MODEL \\\n",
        "            --epochs 15 \\\n",
        "            --train_mode original \\\n",
        "            --test_mode $MOD\n",
        "    done\n",
        "\n",
        "\n",
        "    # BLOCK B: EXPERIMENT 2 & 3 (Shape Adaptation & Domain Mastery)\n",
        "    # Goal: Train on Modified, Test on Original & Same Modified\n",
        "\n",
        "    echo \"[Exp 2 & 3] Training on MODIFIED Data \"\n",
        "\n",
        "    for MOD in \"${MODIFICATIONS[@]}\"; do\n",
        "\n",
        "        # Exp 2: Train Modified -> Test Original (Does the model learn shape?)\n",
        "        echo \"Running: Train $MOD -> Test Original\"\n",
        "        python $SCRIPT_PATH \\\n",
        "            --data_root $DATA_ROOT \\\n",
        "            --output_dir $OUTPUT_DIR \\\n",
        "            --model $MODEL \\\n",
        "            --epochs 15 \\\n",
        "            --train_mode $MOD \\\n",
        "            --test_mode original\n",
        "\n",
        "        # Exp 3: Train Modified -> Test Modified (Theoretical limit)\n",
        "        echo \"Running: Train $MOD -> Test $MOD\"\n",
        "        python $SCRIPT_PATH \\\n",
        "            --data_root $DATA_ROOT \\\n",
        "            --output_dir $OUTPUT_DIR \\\n",
        "            --model $MODEL \\\n",
        "            --epochs 15 \\\n",
        "            --train_mode $MOD \\\n",
        "            --test_mode $MOD\n",
        "    done\n",
        "\n",
        "done\n",
        "\n",
        "echo \"All training experiments finished.\""
      ],
      "metadata": {
        "id": "1mBBzfQmcJBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parse_results.py\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "# Path to your log file\n",
        "log_file = sys.argv[1]\n",
        "\n",
        "results = []\n",
        "current_exp = {}\n",
        "\n",
        "with open(log_file, 'r') as f:\n",
        "    for line in f:\n",
        "        # Detect Experiment Start\n",
        "        # Format: \"Exp: Train on X -> Test on Y | Model: Z\"\n",
        "        match_exp = re.search(r\"Exp: Train on (.*?) -> Test on (.*?) \\| Model: (.*)\", line)\n",
        "        if match_exp:\n",
        "            current_exp = {\n",
        "                'Model': match_exp.group(3).strip(),\n",
        "                'Train': match_exp.group(1).strip(),\n",
        "                'Test': match_exp.group(2).strip()\n",
        "            }\n",
        "\n",
        "        # Detect Final Accuracy\n",
        "        # Format: \"Best Accuracy: 0.9958\"\n",
        "        match_acc = re.search(r\"Best Accuracy: ([\\d\\.]+)\", line)\n",
        "        if match_acc and current_exp:\n",
        "            current_exp['Accuracy'] = float(match_acc.group(1))\n",
        "            results.append(current_exp)\n",
        "            current_exp = {}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"final_results_summary.csv\", index=False)\n",
        "print(\"\\nSaved to final_results_summary.csv\")"
      ],
      "metadata": {
        "id": "YbC368FRc7yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize.py\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "# ARGS\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model_path', type=str, required=True)\n",
        "parser.add_argument('--data_root', type=str, required=True)\n",
        "parser.add_argument('--test_mode', type=str, required=True)\n",
        "parser.add_argument('--model_arch', type=str, default='resnet18')\n",
        "args = parser.parse_args()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1. Setup Data\n",
        "def get_transforms(mode):\n",
        "    trans = [transforms.Resize((224, 224))]\n",
        "    if mode == 'grayscale': trans.append(transforms.Grayscale(num_output_channels=3))\n",
        "    trans.append(transforms.ToTensor())\n",
        "    trans.append(transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
        "    return transforms.Compose(trans)\n",
        "\n",
        "#  Point directly to 'val' folder\n",
        "if args.test_mode in ['original', 'grayscale', 'occlusion']:\n",
        "    base_dir = os.path.join(args.data_root, 'raw', 'imagenette2-160')\n",
        "else:\n",
        "    base_dir = os.path.join(args.data_root, 'processed', args.test_mode)\n",
        "\n",
        "data_dir = os.path.join(base_dir, 'val')\n",
        "\n",
        "dataset = datasets.ImageFolder(data_dir, get_transforms(args.test_mode))\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Loaded {len(dataset.classes)} classes from {data_dir}\")\n",
        "\n",
        "# 2. Load Model\n",
        "if args.model_arch == 'resnet18': model = models.resnet18()\n",
        "else: model = models.resnet101()\n",
        "model.fc = nn.Linear(model.fc.in_features, len(dataset.classes))\n",
        "model.load_state_dict(torch.load(args.model_path, map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 3. Get Predictions\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in loader:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "# 4. Plot\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=dataset.classes, yticklabels=dataset.classes, cmap='Blues')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title(f'Confusion Matrix: {args.test_mode}')\n",
        "plt.savefig(f'confusion_matrix_{args.test_mode}.png')\n",
        "print(f\"Saved confusion_matrix_{args.test_mode}.png\")"
      ],
      "metadata": {
        "id": "Vjz8r-aJdNAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# analyze_failures.py\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "# ARGS\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model_path', type=str, required=True)\n",
        "parser.add_argument('--data_root', type=str, required=True)\n",
        "parser.add_argument('--test_mode', type=str, required=True)\n",
        "args = parser.parse_args()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Transforms\n",
        "trans = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "#  Point directly to 'val' folder\n",
        "if args.test_mode in ['original', 'grayscale', 'occlusion']:\n",
        "    base_dir = os.path.join(args.data_root, 'raw', 'imagenette2-160')\n",
        "else:\n",
        "    base_dir = os.path.join(args.data_root, 'processed', args.test_mode)\n",
        "\n",
        "data_dir = os.path.join(base_dir, 'val')\n",
        "\n",
        "\n",
        "dataset = datasets.ImageFolder(data_dir, trans)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "print(f\"Loaded {len(dataset.classes)} classes from {data_dir}\")\n",
        "\n",
        "# Load Model (ResNet18)\n",
        "model = models.resnet18()\n",
        "model.fc = nn.Linear(model.fc.in_features, len(dataset.classes))\n",
        "model.load_state_dict(torch.load(args.model_path, map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Find Failures\n",
        "failures = []\n",
        "\n",
        "print(\"Searching for failures...\")\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # Find indices where predictions do NOT match labels\n",
        "        wrong_idx = (preds != labels).nonzero(as_tuple=True)[0]\n",
        "\n",
        "        for idx in wrong_idx:\n",
        "            if len(failures) < 5:\n",
        "                # Save the failure: (Image Tensor, True Label, Pred Label)\n",
        "                failures.append((inputs[idx].cpu(), labels[idx].item(), preds[idx].item()))\n",
        "\n",
        "        if len(failures) >= 5:\n",
        "            break\n",
        "\n",
        "# Plot\n",
        "print(f\"Found {len(failures)} failures. Generating image...\")\n",
        "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
        "class_names = dataset.classes\n",
        "\n",
        "for i, (img_tensor, true_idx, pred_idx) in enumerate(failures):\n",
        "    # Un-normalize for display\n",
        "    img = img_tensor.permute(1, 2, 0).numpy()\n",
        "    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "    img = np.clip(img, 0, 1)\n",
        "\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].set_title(f\"True: {class_names[true_idx]}\\nPred: {class_names[pred_idx]}\", color='red')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle(f'Failure Analysis: {args.test_mode}', fontsize=16)\n",
        "plt.savefig('failure_examples.png')\n",
        "print(\"Saved failure_examples.png\")"
      ],
      "metadata": {
        "id": "b0tsIC1TdfnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bG57s42QdvO2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}